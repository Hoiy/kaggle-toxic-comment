{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WuX5lknDOkGp"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "X_tr, X_va, y_tr, y_va = pickle.load( open( \"data/train_data.p\", \"rb\" ) )\n",
    "embedding_matrix = pickle.load( open( \"data/fast_test_emb.p\", \"rb\" ) )\n",
    "maxlen=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "z3l-Z4ZuDtmi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def roc_auc_score(y_true, y_pred):\n",
    "    \"\"\" ROC AUC Score.\n",
    "    Approximates the Area Under Curve score, using approximation based on\n",
    "    the Wilcoxon-Mann-Whitney U statistic.\n",
    "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
    "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
    "    Measures overall performance for a full range of threshold levels.\n",
    "    Arguments:\n",
    "        y_pred: `Tensor`. Predicted values.\n",
    "        y_true: `Tensor` . Targets (labels), a probability distribution.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"RocAucScore\"):\n",
    "\n",
    "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
    "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
    "\n",
    "        pos = tf.expand_dims(pos, 0)\n",
    "        neg = tf.expand_dims(neg, 1)\n",
    "\n",
    "        # original paper suggests performance is robust to exact parameter choice\n",
    "        gamma = 0.2\n",
    "        p     = 3\n",
    "\n",
    "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
    "\n",
    "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
    "\n",
    "        return tf.reduce_sum(tf.pow(-masked, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 493,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4229,
     "status": "ok",
     "timestamp": 1519521305942,
     "user": {
      "displayName": "Hoiy Wong",
      "photoUrl": "//lh4.googleusercontent.com/-FXltFcb84d4/AAAAAAAAAAI/AAAAAAAADDk/fIb0-A-5Ah8/s50-c-k-no/photo.jpg",
      "userId": "103756259079842040806"
     },
     "user_tz": -480
    },
    "id": "rXB3pyCiDvdy",
    "outputId": "6798299b-449d-4cb0-cf70-025af5fa6ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 256, 300)          118436400 \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 256, 256)          77056     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256, 256)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 256, 256)          65792     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256, 256)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 256, 256)          65792     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 256, 256)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 256, 256)          65792     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256, 256)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 118,778,166\n",
      "Trainable params: 341,766\n",
      "Non-trainable params: 118,436,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, Flatten, Activation\n",
    "from keras.layers import Add,Conv1D, MaxPooling1D, Average, Lambda, RepeatVector, LSTM, Bidirectional, GlobalMaxPool1D, Dropout, GRU, Conv1D, Reshape, MaxPooling1D, Concatenate, TimeDistributed\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import non_neg, unit_norm\n",
    "\n",
    "DROPOUT=0.5\n",
    "\n",
    "def get_model():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    \n",
    "    emb = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], trainable=False)(inp)\n",
    "    \n",
    "# roc: 984 val: 425\n",
    "#     emb = TimeDistributed(Dense(256, activation='relu'))(emb)\n",
    "#     emb = Dropout(DROPOUT)(emb)\n",
    "#     emb = TimeDistributed(Dense(256, activation='relu'))(emb)\n",
    "#     emb = Dropout(DROPOUT)(emb)\n",
    "#     emb = TimeDistributed(Dense(256, activation='relu'))(emb)\n",
    "#     emb = Dropout(DROPOUT)(emb)\n",
    "    \n",
    "    emb = TimeDistributed(Dense(256, activation='relu'))(emb)\n",
    "    emb = Dropout(DROPOUT)(emb)\n",
    "    emb = TimeDistributed(Dense(256, activation='relu'))(emb)\n",
    "    emb = Dropout(DROPOUT)(emb)\n",
    "    emb = TimeDistributed(Dense(256, activation='relu'))(emb)\n",
    "    emb = Dropout(DROPOUT)(emb)\n",
    "    emb = TimeDistributed(Dense(256, activation='relu'))(emb)\n",
    "    emb = Dropout(DROPOUT)(emb)\n",
    "\n",
    "    emb = GlobalMaxPool1D()(emb)\n",
    "    #emb = Flatten()(emb)\n",
    "    pred = Dense(256, activation='relu')(emb)\n",
    "    pred = Dropout(DROPOUT)(pred)\n",
    "    final = Dense(6, activation='sigmoid')(pred)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=final)\n",
    "    model.compile(loss=roc_auc_score,\n",
    "                  # optimizer='rmsprop', #9882\n",
    "                  optimizer='adam', #9888\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 734,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 293
      },
      {
       "item_id": 581
      },
      {
       "item_id": 838
      },
      {
       "item_id": 1091
      },
      {
       "item_id": 1343
      },
      {
       "item_id": 1595
      },
      {
       "item_id": 1615
      }
     ]
    },
    "colab_type": "code",
    "id": "qYchwqHeDxQV",
    "outputId": "dadfcd1a-1b0f-4673-e694-484d4e9e125c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoiy927/.local/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:97: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 9148.3286 - acc: 0.7385roc-auc_val: 0.9463                                                                                                    \n",
      "127657/127657 [==============================] - 204s 2ms/step - loss: 9103.4607 - acc: 0.7392 - val_loss: 1918.2615 - val_acc: 0.9943\n",
      "Epoch 2/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 1568.7088 - acc: 0.9123roc-auc_val: 0.9572                                                                                                    \n",
      "127657/127657 [==============================] - 202s 2ms/step - loss: 1562.9940 - acc: 0.9123 - val_loss: 1575.7276 - val_acc: 0.9943\n",
      "Epoch 3/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 1160.5527 - acc: 0.9572roc-auc_val: 0.9612                                                                                                    \n",
      "127657/127657 [==============================] - 199s 2ms/step - loss: 1156.5490 - acc: 0.9571 - val_loss: 1759.6333 - val_acc: 0.9943\n",
      "Epoch 4/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 981.1057 - acc: 0.9768roc-auc_val: 0.961                                                                                                    \n",
      "127657/127657 [==============================] - 198s 2ms/step - loss: 978.0269 - acc: 0.9769 - val_loss: 1698.5043 - val_acc: 0.9943\n",
      "Epoch 5/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 883.2200 - acc: 0.9869roc-auc_val: 0.9619                                                                                                    \n",
      "127657/127657 [==============================] - 198s 2ms/step - loss: 881.0147 - acc: 0.9869 - val_loss: 1799.6993 - val_acc: 0.9943\n",
      "Epoch 6/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 821.9625 - acc: 0.9906roc-auc_val: 0.9615                                                                                                    \n",
      "127657/127657 [==============================] - 198s 2ms/step - loss: 819.4763 - acc: 0.9906 - val_loss: 1864.5702 - val_acc: 0.9943\n",
      "Epoch 7/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 794.7771 - acc: 0.9899roc-auc_val: 0.9602                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 792.1925 - acc: 0.9899 - val_loss: 1672.2855 - val_acc: 0.9943\n",
      "Epoch 8/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 754.1294 - acc: 0.9911roc-auc_val: 0.9619                                                                                                    \n",
      "127657/127657 [==============================] - 198s 2ms/step - loss: 751.6513 - acc: 0.9911 - val_loss: 1987.0077 - val_acc: 0.9943\n",
      "Epoch 9/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 724.5092 - acc: 0.9918roc-auc_val: 0.9609                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 721.8935 - acc: 0.9918 - val_loss: 1862.6660 - val_acc: 0.9943\n",
      "Epoch 10/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 696.1370 - acc: 0.9922roc-auc_val: 0.9621                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 694.5653 - acc: 0.9922 - val_loss: 1743.6407 - val_acc: 0.9943\n",
      "Epoch 11/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 659.6965 - acc: 0.9928roc-auc_val: 0.9609                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 657.6641 - acc: 0.9928 - val_loss: 1909.5405 - val_acc: 0.9943\n",
      "Epoch 12/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 676.4808 - acc: 0.9929roc-auc_val: 0.9633                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 674.5839 - acc: 0.9928 - val_loss: 1907.4366 - val_acc: 0.9943\n",
      "Epoch 13/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 637.3371 - acc: 0.9934roc-auc_val: 0.9626                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 635.0958 - acc: 0.9934 - val_loss: 1885.8778 - val_acc: 0.9943\n",
      "Epoch 14/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 641.9271 - acc: 0.9931roc-auc_val: 0.9623                                                                                                    \n",
      "127657/127657 [==============================] - 202s 2ms/step - loss: 639.4675 - acc: 0.9931 - val_loss: 1563.5489 - val_acc: 0.9943\n",
      "Epoch 15/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 612.1679 - acc: 0.9930roc-auc_val: 0.961                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 610.4320 - acc: 0.9930 - val_loss: 1812.6964 - val_acc: 0.9943\n",
      "Epoch 16/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 601.0473 - acc: 0.9931roc-auc_val: 0.963                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 599.0081 - acc: 0.9931 - val_loss: 1748.9721 - val_acc: 0.9943\n",
      "Epoch 17/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 590.0101 - acc: 0.9931roc-auc_val: 0.9635                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 588.2780 - acc: 0.9931 - val_loss: 1687.5909 - val_acc: 0.9943\n",
      "Epoch 18/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 589.8094 - acc: 0.9934roc-auc_val: 0.9631                                                                                                    \n",
      "127657/127657 [==============================] - 198s 2ms/step - loss: 587.9899 - acc: 0.9934 - val_loss: 1784.0339 - val_acc: 0.9943\n",
      "Epoch 19/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 580.8047 - acc: 0.9934roc-auc_val: 0.9625                                                                                                    \n",
      "127657/127657 [==============================] - 198s 2ms/step - loss: 579.4215 - acc: 0.9934 - val_loss: 1625.8571 - val_acc: 0.9943\n",
      "Epoch 20/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 570.0570 - acc: 0.9935roc-auc_val: 0.9656                                                                                                    \n",
      "127657/127657 [==============================] - 198s 2ms/step - loss: 568.2930 - acc: 0.9935 - val_loss: 1601.4465 - val_acc: 0.9943\n",
      "Epoch 21/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 556.6251 - acc: 0.9933roc-auc_val: 0.9652                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 554.9340 - acc: 0.9933 - val_loss: 1866.4854 - val_acc: 0.9943\n",
      "Epoch 22/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 559.2627 - acc: 0.9936roc-auc_val: 0.9649                                                                                                    \n",
      "127657/127657 [==============================] - 201s 2ms/step - loss: 557.6508 - acc: 0.9936 - val_loss: 1560.1981 - val_acc: 0.9943\n",
      "Epoch 23/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 543.3223 - acc: 0.9934roc-auc_val: 0.9664                                                                                                    \n",
      "127657/127657 [==============================] - 198s 2ms/step - loss: 541.3713 - acc: 0.9934 - val_loss: 1630.6828 - val_acc: 0.9943\n",
      "Epoch 24/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 539.9512 - acc: 0.9932roc-auc_val: 0.9669                                                                                                    \n",
      "127657/127657 [==============================] - 201s 2ms/step - loss: 538.5507 - acc: 0.9932 - val_loss: 1505.0524 - val_acc: 0.9943\n",
      "Epoch 25/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 522.4180 - acc: 0.9934roc-auc_val: 0.9688                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 520.9944 - acc: 0.9934 - val_loss: 1558.8025 - val_acc: 0.9943\n",
      "Epoch 26/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 520.9417 - acc: 0.9935roc-auc_val: 0.9672                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 519.4147 - acc: 0.9935 - val_loss: 1625.2688 - val_acc: 0.9943\n",
      "Epoch 27/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 508.4493 - acc: 0.9935roc-auc_val: 0.9648                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 507.2822 - acc: 0.9935 - val_loss: 1799.6797 - val_acc: 0.9943\n",
      "Epoch 28/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 509.7418 - acc: 0.9936roc-auc_val: 0.9677                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 508.1544 - acc: 0.9936 - val_loss: 1808.2764 - val_acc: 0.9943\n",
      "Epoch 29/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 504.8560 - acc: 0.9933roc-auc_val: 0.9658                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 503.3104 - acc: 0.9933 - val_loss: 1509.5570 - val_acc: 0.9943\n",
      "Epoch 30/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 507.3642 - acc: 0.9932roc-auc_val: 0.9696                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 505.7713 - acc: 0.9932 - val_loss: 1513.1909 - val_acc: 0.9943\n",
      "Epoch 31/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 494.1792 - acc: 0.9934roc-auc_val: 0.9677                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 492.2722 - acc: 0.9934 - val_loss: 1745.8022 - val_acc: 0.9943\n",
      "Epoch 32/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 477.8526 - acc: 0.9933roc-auc_val: 0.9645                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 476.1391 - acc: 0.9934 - val_loss: 1771.6356 - val_acc: 0.9943\n",
      "Epoch 33/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 492.5559 - acc: 0.9929roc-auc_val: 0.9668                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 491.6921 - acc: 0.9929 - val_loss: 1628.3033 - val_acc: 0.9943\n",
      "Epoch 34/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 477.7366 - acc: 0.9933roc-auc_val: 0.9577                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 476.0850 - acc: 0.9933 - val_loss: 1911.2438 - val_acc: 0.9943\n",
      "Epoch 35/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 470.2938 - acc: 0.9933roc-auc_val: 0.9654                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 468.7981 - acc: 0.9933 - val_loss: 1681.1319 - val_acc: 0.9943\n",
      "Epoch 36/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 459.9853 - acc: 0.9930roc-auc_val: 0.9666                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 458.6377 - acc: 0.9930 - val_loss: 1762.4070 - val_acc: 0.9943\n",
      "Epoch 37/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 474.7431 - acc: 0.9928roc-auc_val: 0.9653                                                                                                    \n",
      "127657/127657 [==============================] - 197s 2ms/step - loss: 473.1370 - acc: 0.9928 - val_loss: 1604.9797 - val_acc: 0.9943\n",
      "Epoch 38/2000\n",
      "126976/127657 [============================>.] - ETA: 0s - loss: 453.1149 - acc: 0.9933roc-auc_val: 0.9682                                                                                                    \n",
      "127657/127657 [==============================] - 201s 2ms/step - loss: 451.7884 - acc: 0.9933 - val_loss: 1452.4641 - val_acc: 0.9943\n",
      "Epoch 39/2000\n",
      " 84992/127657 [==================>...........] - ETA: 1:00 - loss: 451.0720 - acc: 0.9933"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "np.random.seed(777)\n",
    "batch_size = 1024\n",
    "epochs = 2000\n",
    "\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        \n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "        \n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):        \n",
    "        #y_pred = self.model.predict(self.x, batch_size=batch_size)\n",
    "        #roc = metrics.roc_auc_score(self.y, y_pred)\n",
    "        \n",
    "        y_pred_val = self.model.predict(self.x_val, batch_size=batch_size)\n",
    "        roc_val = metrics.roc_auc_score(self.y_val, y_pred_val)\n",
    "        \n",
    "        print('roc-auc_val: %s' % str(round(roc_val,4)),end=100*' '+'\\n')\n",
    "        \n",
    "        #print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    " \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return   \n",
    "\n",
    "#from keras.models import load_model\n",
    "#model = load_model('./weights_base.best.hdf5', custom_objects={'roc_auc_score': roc_auc_score})\n",
    "file_path=\"weights_base.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', save_best_only=True)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20, verbose=1)\n",
    "#\n",
    "callbacks_list = [checkpoint, early, roc_callback((X_tr, y_tr), (X_va, y_va))]\n",
    "#callbacks_list = [checkpoint, early]\n",
    "model.fit(\n",
    "    X_tr,\n",
    "    y_tr, \n",
    "    class_weight=None, \n",
    "    validation_data=(X_va, y_va), \n",
    "    shuffle=True, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 351,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 638,
     "status": "error",
     "timestamp": 1519436268268,
     "user": {
      "displayName": "Hoiy Wong",
      "photoUrl": "//lh4.googleusercontent.com/-FXltFcb84d4/AAAAAAAAAAI/AAAAAAAADDk/fIb0-A-5Ah8/s50-c-k-no/photo.jpg",
      "userId": "103756259079842040806"
     },
     "user_tz": -480
    },
    "id": "mtkHmdhEOHug",
    "outputId": "f5b085a4-449e-451f-b2f5-771d56ac893a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ee0792aab60c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo install keras, click the button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def roc_auc_score(y_true, y_pred):\n",
    "    \"\"\" ROC AUC Score.\n",
    "    Approximates the Area Under Curve score, using approximation based on\n",
    "    the Wilcoxon-Mann-Whitney U statistic.\n",
    "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
    "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
    "    Measures overall performance for a full range of threshold levels.\n",
    "    Arguments:\n",
    "        y_pred: `Tensor`. Predicted values.\n",
    "        y_true: `Tensor` . Targets (labels), a probability distribution.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"RocAucScore\"):\n",
    "\n",
    "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
    "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
    "\n",
    "        pos = tf.expand_dims(pos, 0)\n",
    "        neg = tf.expand_dims(neg, 1)\n",
    "\n",
    "        # original paper suggests performance is robust to exact parameter choice\n",
    "        gamma = 0.2\n",
    "        p     = 3\n",
    "\n",
    "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
    "\n",
    "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
    "\n",
    "        return tf.reduce_sum(tf.pow(-masked, p))\n",
    "\n",
    "model = load_model('./weights_base.best.hdf5', custom_objects={'roc_auc_score': roc_auc_score})\n",
    "X_te = pickle.load( open( \"test_data.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44156,
     "status": "ok",
     "timestamp": 1519035924114,
     "user": {
      "displayName": "Hoiy Wong",
      "photoUrl": "//lh4.googleusercontent.com/-FXltFcb84d4/AAAAAAAAAAI/AAAAAAAADDk/fIb0-A-5Ah8/s50-c-k-no/photo.jpg",
      "userId": "103756259079842040806"
     },
     "user_tz": -480
    },
    "id": "wTEURiafBjj1",
    "outputId": "a0e9fbe5-4730-4689-df48-5e5af2bf0c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 44s 284us/step\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict([X_te], batch_size=1024, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "urZC-oFJC91_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "sample_submission[list_classes] = y_test\n",
    "sample_submission.to_csv(\"dicnn_9863.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 876,
     "status": "ok",
     "timestamp": 1519035966366,
     "user": {
      "displayName": "Hoiy Wong",
      "photoUrl": "//lh4.googleusercontent.com/-FXltFcb84d4/AAAAAAAAAAI/AAAAAAAADDk/fIb0-A-5Ah8/s50-c-k-no/photo.jpg",
      "userId": "103756259079842040806"
     },
     "user_tz": -480
    },
    "id": "6dAEiwZgA-jl",
    "outputId": "28b88627-ba03-4aa5-bbf7-5ef4bf8665ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 20M Feb 19 10:25 dicnn_9863.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -laht dicnn_9863.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21446,
     "status": "ok",
     "timestamp": 1519036003304,
     "user": {
      "displayName": "Hoiy Wong",
      "photoUrl": "//lh4.googleusercontent.com/-FXltFcb84d4/AAAAAAAAAAI/AAAAAAAADDk/fIb0-A-5Ah8/s50-c-k-no/photo.jpg",
      "userId": "103756259079842040806"
     },
     "user_tz": -480
    },
    "id": "2csR-rwhDh9x",
    "outputId": "5278feff-7f3e-410a-8d73-acd8f5a5d106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9818\n"
     ]
    }
   ],
   "source": [
    "!kg submit dicnn_9863.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 187,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 921,
     "status": "ok",
     "timestamp": 1519436288577,
     "user": {
      "displayName": "Hoiy Wong",
      "photoUrl": "//lh4.googleusercontent.com/-FXltFcb84d4/AAAAAAAAAAI/AAAAAAAADDk/fIb0-A-5Ah8/s50-c-k-no/photo.jpg",
      "userId": "103756259079842040806"
     },
     "user_tz": -480
    },
    "id": "OIM3hf4KDluy",
    "outputId": "11087cb3-e1d3-4742-e8a0-fc6f03c2c4a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 36K\n",
      "drwx------ 4 root root 4.0K Feb 24 01:34 .cache\n",
      "drwxr-xr-x 1 root root 4.0K Feb 24 01:34 .\n",
      "drwxr-xr-x 3 root root 4.0K Feb 24 01:34 .config\n",
      "drwxr-xr-x 5 root root 4.0K Feb 24 01:34 .ipython\n",
      "drwx------ 3 root root 4.0K Feb 24 01:30 .local\n",
      "drwxr-xr-x 4 root root 4.0K Feb 24 01:30 .forever\n",
      "-rw------- 1 root root 1.0K Feb 24 01:30 .rnd\n",
      "drwxr-xr-x 1 root root 4.0K Feb 24 01:30 ..\n",
      "drwxr-xr-x 1 root root 4.0K Feb 24 01:29 datalab\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 374,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1262,
     "status": "ok",
     "timestamp": 1519494801009,
     "user": {
      "displayName": "Hoiy Wong",
      "photoUrl": "//lh4.googleusercontent.com/-FXltFcb84d4/AAAAAAAAAAI/AAAAAAAADDk/fIb0-A-5Ah8/s50-c-k-no/photo.jpg",
      "userId": "103756259079842040806"
     },
     "user_tz": -480
    },
    "id": "BCi3oQZWhrYv",
    "outputId": "0248b641-4747-4182-ef6e-e303b79d3eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9.5G\n",
      "-rw-r--r--  1 root root 457M Feb 24 17:03 weights_base.best.hdf5\n",
      "drwxr-xr-x  1 root root 4.0K Feb 24 12:58 .\n",
      "drwx------  3 root root 4.0K Feb 24 12:58 .nv\n",
      "drwxr-xr-x  2 root root 4.0K Feb 24 12:58 .keras\n",
      "drwx------  2 root root 4.0K Feb 24 12:57 .kaggle-cli\n",
      "drwx------  4 root root 4.0K Feb 24 12:57 .local\n",
      "drwxr-xr-x 10 root root 4.0K Feb 24 12:57 fastText\n",
      "-rw-r--r--  1 root root 7.4G Feb 24 12:56 wiki.en.bin.gz\n",
      "-rw-r--r--  1 root root 164M Feb 24 12:55 train_data.p\n",
      "-rw-r--r--  1 root root 150M Feb 24 12:55 test_data.p\n",
      "-rw-r--r--  1 root root 904M Feb 24 12:55 fast_test_emb.p\n",
      "-rw-r--r--  1 root root 460M Feb 24 12:55 379.h5\n",
      "drwxr-xr-x  3 root root 4.0K Feb 24 12:55 .gsutil\n",
      "drwxr-xr-x  1 root root 4.0K Feb 24 12:55 datalab\n",
      "drwx------  4 root root 4.0K Feb 24 12:54 .cache\n",
      "drwxr-xr-x  3 root root 4.0K Feb 24 12:54 .config\n",
      "drwxr-xr-x  5 root root 4.0K Feb 24 12:54 .ipython\n",
      "drwxr-xr-x  4 root root 4.0K Feb 24 12:20 .forever\n",
      "-rw-------  1 root root 1.0K Feb 24 12:20 .rnd\n",
      "drwxr-xr-x  1 root root 4.0K Feb 24 12:19 ..\n"
     ]
    }
   ],
   "source": [
    "!ls -laht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "scD-wsZX8kQy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "test_loss312_valloss_313_epoch_50_localroc_9894.ipynb",
   "provenance": [
    {
     "file_id": "1QdH-38lSy2DrTpAtPOac4B56trjdR5I0",
     "timestamp": 1519217708186
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
